{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:13:48.729221Z",
     "start_time": "2019-01-19T15:13:48.376629Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import csv, json\n",
    "import ogr, osr\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict, Counter\n",
    "from matplotlib import pyplot as plt, figure\n",
    "import copy\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "import overpy\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ogr.UseExceptions()\n",
    "osr.UseExceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:13:49.842126Z",
     "start_time": "2019-01-19T15:13:49.810826Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parent directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Child directories\n",
    "boundaries_dir = os.path.join(cwd, 'boundaries')\n",
    "gtfs_dir = os.path.join(cwd, 'gtfs')\n",
    "output_dir = os.path.join(cwd, 'output')\n",
    "\n",
    "# Create output directory\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:13:51.686950Z",
     "start_time": "2019-01-19T15:13:51.615868Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dict_to_geojson(data, out_path, geom_field, fields_key=None, epsg_id=None):\n",
    "    \n",
    "    # Create path\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "        \n",
    "    # Get GeoJSON driver\n",
    "    driver = ogr.GetDriverByName('GeoJSON')\n",
    "    \n",
    "    ds = driver.CreateDataSource(out_path)\n",
    "    \n",
    "    spatial_ref = osr.SpatialReference()\n",
    "    if epsg_id:\n",
    "        spatial_ref.ImportFromEPSG(4326)\n",
    "    else:\n",
    "        spatial_ref.ImportFromEPSG(epsg_id)\n",
    "        \n",
    "    # Get geom type\n",
    "    geom_type = data[0][geom_field].GetGeometryType()\n",
    "    \n",
    "    layer = ds.CreateLayer(out_path, geom_type=geom_type, srs=spatial_ref)\n",
    "    \n",
    "    # Create the fields\n",
    "    if fields_key:\n",
    "        field_names = data[0][fields_key].keys()\n",
    "        for i, field_name in enumerate(field_names): \n",
    "            layer.CreateField(ogr.FieldDefn(field_name, ogr.OFTString))\n",
    "    \n",
    "    layer_defn = layer.GetLayerDefn()\n",
    "    \n",
    "    for item in data:\n",
    "        feature = ogr.Feature(layer_defn)\n",
    "        \n",
    "        if fields_key:\n",
    "            for field_name in field_names:\n",
    "                feature.SetField(field_name, item[fields_key][field_name])\n",
    "        \n",
    "        feature.SetGeometry(item[geom_field])\n",
    "        \n",
    "        layer.CreateFeature(feature)\n",
    "        \n",
    "def objects_to_xml(path, bounds=None, nodes=None, ways=None, relations=None):\n",
    "    root = ET.Element(\"osm\")\n",
    "    pass\n",
    "\n",
    "def reproject_geometry(geom, in_epsg, out_epsg, return_wkt=False):\n",
    "    import ogr, osr\n",
    "\n",
    "    source = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(in_epsg)\n",
    "\n",
    "    target = osr.SpatialReference()\n",
    "    target.ImportFromEPSG(out_epsg)\n",
    "\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "    geom.Transform(transform)\n",
    "\n",
    "    if return_wkt:\n",
    "        return geom.ExportToWkt()\n",
    "    else:\n",
    "        return geom\n",
    "    \n",
    "def write_geometry_to_geojson(geom, out_path):\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "    \n",
    "    driver = ogr.GetDriverByName('GeoJSON')\n",
    "    ds = driver.CreateDataSource(out_path)\n",
    "    \n",
    "    geom_type = geom.GetGeometryType()\n",
    "    \n",
    "    layer = ds.CreateLayer(out_path, geom_type=geom_type)\n",
    "    layer_defn = layer.GetLayerDefn()\n",
    "    \n",
    "    feature = ogr.Feature(layer_defn)\n",
    "    feature.SetGeometry(geom)\n",
    "    layer.CreateFeature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:18:14.967932Z",
     "start_time": "2019-01-13T08:18:14.957921Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Overpy Query Templates\n",
    "\n",
    "*Overpass doesn't allow Geocoding like Turbo Overpass does so I've gathered the city relation ids beforehand to use directly with overpass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:13:53.104800Z",
     "start_time": "2019-01-19T15:13:53.075750Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "api = overpy.Overpass()\n",
    "\n",
    "relation_to_area_factor = 3600000000\n",
    "\n",
    "region_ids = {\n",
    "    \"Laval\": 3532125 + relation_to_area_factor,\n",
    "    \"Montreal\": 1571328 + relation_to_area_factor\n",
    "}\n",
    "\n",
    "\n",
    "tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "      node[\"amenity\"=\"pub\"](area.searchArea);\n",
    "      way[\"amenity\"=\"pub\"](area.searchArea);\n",
    "      relation[\"amenity\"=\"pub\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bus_stop_tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "    node[\"highway\"=\"bus_stop\"](area.searchArea);\n",
    "    way[\"highway\"=\"platform\"](area.searchArea);\n",
    "\n",
    "    node[\"public_transport\"=\"platform\"][\"bus\"=\"yes\"](area.searchArea);\n",
    "    node[\"public_transport\"=\"stop_position\"][\"bus\"=\"yes\"](area.searchArea);\n",
    "    \n",
    "    way[\"amenity\"=\"shelter\"](area.searchArea);\n",
    "    node[\"amenity\"=\"shelter\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\"\n",
    "\n",
    "service_route_tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "    relation[\"type\"=\"route\"][\"route\"=\"bus\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Boundaries into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:13:55.550238Z",
     "start_time": "2019-01-19T15:13:55.465629Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5bdd6740145ac99aeedcc68406708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "boundaries = {}\n",
    "\n",
    "boundary_files = os.listdir(boundaries_dir)\n",
    "\n",
    "for boundary_file in tqdm_notebook(boundary_files):\n",
    "    path = os.path.join(boundaries_dir, boundary_file)\n",
    "    city = boundary_file[:-4]\n",
    "    \n",
    "    with open(path) as f:\n",
    "        geom = ogr.CreateGeometryFromWkt(f.read())\n",
    "        boundaries[city] = geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get existing data from OSM using OverPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:03.662880Z",
     "start_time": "2019-01-19T15:13:57.138495Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "existing_stops = []\n",
    "\n",
    "stops_result_laval = api.query(bus_stop_tmpl.format(region_ids['Laval']))\n",
    "stops_result_montreal = api.query(bus_stop_tmpl.format(region_ids['Montreal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:04.881331Z",
     "start_time": "2019-01-19T15:14:04.812817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for node in stops_result_laval.nodes:\n",
    "    existing_stop = {\n",
    "        'id': node.id,\n",
    "        'lat': node.lat,\n",
    "        'lon': node.lon,\n",
    "        'tags': node.tags,\n",
    "        'city': 'Laval'\n",
    "    }\n",
    "    existing_stops.append(existing_stop)\n",
    "    \n",
    "for node in stops_result_montreal.nodes:\n",
    "    existing_stop = {\n",
    "        'id': node.id,\n",
    "        'lat': node.lat,\n",
    "        'lon': node.lon,\n",
    "        'tags': node.tags,\n",
    "        'city': 'Montreal'\n",
    "    }\n",
    "    existing_stops.append(existing_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load GTFS text files to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:10.415308Z",
     "start_time": "2019-01-19T15:14:06.635458Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db535f7de9bf4cbeb6272565bf5e4f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gtfs_data = {}\n",
    "\n",
    "filenames = os.listdir(gtfs_dir)\n",
    "\n",
    "for filename in tqdm_notebook(filenames):\n",
    "    table_name = filename[:-4]\n",
    "    path = os.path.join(gtfs_dir, filename)\n",
    "    gtfs_data[table_name] = {\n",
    "        \"path\": path,\n",
    "    }\n",
    "\n",
    "    with open(path, encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        field_names = next(reader)\n",
    "        gtfs_data[table_name][\"field_names\"] = field_names\n",
    "        \n",
    "        first_data_row = next(reader)\n",
    "        field_types = []\n",
    "        for i, item in enumerate(first_data_row):\n",
    "            if len(item) == 1:\n",
    "                field_types.append(ogr.OFTInteger)\n",
    "            elif 'lat' in field_names[i] or 'lon' in field_names[i]:\n",
    "                field_types.append(ogr.OFTReal)\n",
    "            else:\n",
    "                field_types.append(ogr.OFTString)\n",
    "        gtfs_data[table_name][\"field_types\"] = field_types\n",
    "        \n",
    "        dict_reader = csv.DictReader(csvfile, fieldnames=field_names)\n",
    "        data = [row for row in dict_reader]\n",
    "        gtfs_data[table_name][\"data\"] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Print the dictionary information for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:12.126880Z",
     "start_time": "2019-01-19T15:14:12.112322Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# table: # field names\n",
      "calendar_dates: ['service_id', 'date', 'exception_type']\n",
      "[4, 4, 0]\n",
      "\n",
      "trips: ['route_id', 'service_id', 'trip_id', 'block_id', 'shape_id', 'trip_headsign']\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "\n",
      "routes: ['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type', 'route_url', 'route_headsign', 'route_color', 'route_text_color']\n",
      "[4, 4, 4, 2, 0, 4, 4, 4, 4]\n",
      "\n",
      "stops: ['stop_id', 'stop_code', 'stop_name', 'stop_lon', 'stop_lat', 'location_type', 'stop_display', 'stop_abribus']\n",
      "[4, 4, 4, 2, 2, 0, 0, 0]\n",
      "\n",
      "stop_times: ['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence', 'pickup_type', 'drop_off_type']\n",
      "[4, 4, 4, 4, 0, 0, 0]\n",
      "\n",
      "shapes: ['shape_id', 'shape_pt_lat', 'shape_pt_lon', 'shape_pt_sequence']\n",
      "[4, 2, 2, 4]\n",
      "\n",
      "agency: ['agency_id', 'agency_name', 'agency_url', 'agency_timezone', 'agency_lang']\n",
      "[4, 4, 4, 4, 4]\n",
      "\n",
      "calendar: ['service_id', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'start_date', 'end_date']\n",
      "[4, 0, 0, 0, 0, 0, 0, 0, 4, 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# table: # field names')\n",
    "for key, value in gtfs_data.items():\n",
    "    print('{}: {}\\n{}\\n'.format(key, value['field_names'], value['field_types']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate the stops file\n",
    "1. Split the stop code from the name\n",
    "2. Check for name uniqueness\n",
    "3. Check for location uniqueness (with proximity tolerance - optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Visualize the stop **names** and **codes** frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:14.625170Z",
     "start_time": "2019-01-19T15:14:14.540701Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325ad9ac765d4cfda08372ab2c565c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5745), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stops = gtfs_data['stops']['data']\n",
    "\n",
    "unique_stops = []\n",
    "stop_name_counter = Counter()\n",
    "stop_code_counter = Counter()\n",
    "\n",
    "for stop in tqdm_notebook(stops):\n",
    "    real_name = stop['stop_name'].split('[')[0].strip()\n",
    "    stop_code = stop['stop_code']\n",
    "    stop_name_counter[real_name] += 1\n",
    "    stop_code_counter[stop_code] += 1\n",
    "    \n",
    "names, name_counts = zip(*stop_name_counter.items())\n",
    "codes, code_counts = zip(*stop_code_counter.items())\n",
    "\n",
    "bar_height = 10\n",
    "\n",
    "plot_specs = {\n",
    "    'names': {\n",
    "        'positions': np.arange(len(names)),\n",
    "        'bar_spacing': 2 * np.arange(len(names)) * bar_height,\n",
    "        'labels': names,\n",
    "        'values': name_counts,\n",
    "        'title': 'Distribution of stop names'\n",
    "    },\n",
    "    'codes': {\n",
    "        'positions': np.arange(len(codes)),\n",
    "        'bar_spacing': 2 * np.arange(len(codes)) * bar_height,\n",
    "        'labels': codes,\n",
    "        'values': code_counts,\n",
    "        'title': 'Distribution of stop codes'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:14:16.229655Z",
     "start_time": "2019-01-19T15:14:16.219594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Can't get this to work....moving on\n",
    "\n",
    "# # plt.figure(figsize=(50,30))\n",
    "# plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "# for i, (plot_name, spec) in enumerate(plot_specs.items(), 1):\n",
    "#     plt.subplot(1, 2, i)\n",
    "#     plt.barh(spec['positions'], spec['values'], height=bar_height)\n",
    "#     plt.yticks(spec['bar_spacing'], spec['labels'])\n",
    "#     plt.title(spec['title'])\n",
    "#     plt.autoscale()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:30:29.191793Z",
     "start_time": "2019-01-12T13:30:29.180259Z"
    }
   },
   "source": [
    "#### Create unique stops list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:23:17.400349Z",
     "start_time": "2019-01-19T15:17:26.744636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295b500525914277aa1ab947d2b09ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2773), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stops = gtfs_data['stops']['data']\n",
    "\n",
    "# existing_count_laval = 0\n",
    "# existing_count_montreal = 0\n",
    "existing_count_total = 0\n",
    "\n",
    "# Extent\n",
    "multi_point = ogr.Geometry(ogr.wkbMultiPoint)\n",
    "\n",
    "# Dictionary to group stops by unique location\n",
    "unique_locations = defaultdict(list)\n",
    "\n",
    "# List of stops rearranged with uniqueness\n",
    "unique_stops = []\n",
    "# unique_stops_gtfs = []\n",
    "# unique_stops_osm = []\n",
    "# unique_stops_map = []  # GTFS -> OSM\n",
    "\n",
    "# Aggregate unique locations\n",
    "for stop in stops:\n",
    "    unique_locations[(stop['stop_lon'], stop['stop_lat'])].append(stop)\n",
    "\n",
    "# Aggregate attributes using unique locations into new stop objects\n",
    "for i, (unique_location, stops) in enumerate(tqdm_notebook(unique_locations.items()), 1):\n",
    "\n",
    "    ids = list(set([stop['stop_id'] for stop in stops]))\n",
    "    codes = list(set([stop['stop_code'] for stop in stops]))\n",
    "\n",
    "    lon = float(stops[0]['stop_lon'])\n",
    "    lat = float(stops[0]['stop_lat'])\n",
    "\n",
    "    # Create point to add to MultiPoint (for JOSM extent later...)\n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    point.AddPoint(lon, lat)\n",
    "    multi_point.AddGeometry(point)\n",
    "\n",
    "#     # Create the unique stop maintaining GTFS file format\n",
    "#     unique_stop_gtfs = {\n",
    "#\n",
    "#         'geom': point\n",
    "#     }\n",
    "\n",
    "    # Create the unique stop according to JOSM format\n",
    "\n",
    "    action = None\n",
    "\n",
    "    # While checking for:\n",
    "    # 1. What city it is ine\n",
    "    # 2. If a node with the same geometry already exists in OSM\n",
    "    # 2.1 If node is in Laval, replace the tags\n",
    "    # 2.2 If node is in Montreal, append, code and name tags\n",
    "\n",
    "    # Get the city of the GTFS stop\n",
    "    city = None\n",
    "    for city_name, city_geom in boundaries.items():\n",
    "        if point.Intersects(city_geom):\n",
    "            city = city_name\n",
    "\n",
    "    osm_id = None\n",
    "    osm_lat = None\n",
    "    osm_lon = None\n",
    "\n",
    "    # Determine if node already exists\n",
    "    for existing_stop in existing_stops:\n",
    "        existing_point = ogr.Geometry(ogr.wkbPoint)\n",
    "        existing_point.AddPoint(\n",
    "            float(existing_stop['lon']), float(existing_stop['lat']))\n",
    "\n",
    "        if point.Equals(existing_point):\n",
    "            #             print('Equal point found')\n",
    "            existing_count_total += 1\n",
    "\n",
    "            osm_id = existing_stop['id']\n",
    "            osm_lat = existing_stop['lat']\n",
    "            osm_lon = existing_stop['lon']\n",
    "            action = 'modify'\n",
    "\n",
    "#             print(osm_id)\n",
    "        else:\n",
    "            osm_id = str(i * -1)\n",
    "            osm_lat = str(lat)\n",
    "            osm_lon = str(lon)\n",
    "\n",
    "    unique_stop = {\n",
    "        # props\n",
    "        'props': {\n",
    "            'id': osm_id,\n",
    "            'lon': osm_lon,\n",
    "            'lat': osm_lat,\n",
    "        },\n",
    "        # tags\n",
    "        'tags': {\n",
    "            'bus': 'yes',\n",
    "            'highway': 'bus_stop',\n",
    "            'name': stops[0]['stop_name'].split('[')[0].strip(),\n",
    "            'public_transport': 'platform',\n",
    "            'ref': ';'.join(codes),\n",
    "            'shelter': 'yes' if stops[0]['stop_abribus'] == '1' else 'no',\n",
    "        },\n",
    "        \"geom\": point,\n",
    "        # GTFS fields\n",
    "        \"gtfs_props\": {\n",
    "            'stop_id': ','.join(ids),\n",
    "            'stop_code': ','.join(codes),\n",
    "            'stop_name': stops[0]['stop_name'].split('[')[0].strip(),\n",
    "            'stop_lon': lon,\n",
    "            'stop_lat': lat,\n",
    "            'location_type': stops[0]['location_type'],\n",
    "            'stop_display': stops[0]['stop_display'],\n",
    "            'stop_abribus': stops[0]['stop_abribus'],\n",
    "        }\n",
    "    }\n",
    "\n",
    "#     unique_stops_map.append((ids, osm_id))\n",
    "\n",
    "    if action:\n",
    "        unique_stop['props']['action'] = action\n",
    "\n",
    "#     unique_stops_gtfs.append(unique_stop_gtfs)\n",
    "    unique_stops.append(unique_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Merge stops by proximity (tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:24:10.569052Z",
     "start_time": "2019-01-19T15:24:06.851864Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer_distance = 2  # meter\n",
    "multi_point_utm = reproject_geometry(multi_point.Clone(), 4326, 32618)\n",
    "buffered_points = multi_point_utm.Buffer(5)\n",
    "buffered_points_dissolved = buffered_points.UnionCascaded()\n",
    "buffered_points_dissolved_geo = reproject_geometry(buffered_points_dissolved.Clone(), 32618, 4326)\n",
    "\n",
    "buffers_file = os.path.join(output_dir, 'buffers.geojson')\n",
    "write_geometry_to_geojson(buffered_points_dissolved_geo, buffers_file)\n",
    "\n",
    "stops_file = os.path.join(output_dir, 'gtfs_stops.geojson')\n",
    "dict_to_geojson(unique_stops, stops_file, 'geom', fields_key='gtfs_props', epsg_id=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:41:07.558078Z",
     "start_time": "2019-01-19T15:39:05.445276Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d06edb79f2476daf47fb15d307d70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique stops before merge: 2773\n",
      "Unique stops after merge: 2681\n"
     ]
    }
   ],
   "source": [
    "unique_stops_merged = []\n",
    "\n",
    "for i, buffer in tqdm_notebook(enumerate(buffered_points_dissolved_geo)):\n",
    "    stops_to_merge = []\n",
    "    for stop in unique_stops:\n",
    "        if stop['geom'].Within(buffer):\n",
    "            stops_to_merge.append(stop)\n",
    "            \n",
    "    if len(stops_to_merge) > 1:\n",
    "        new_stop = stops_to_merge[0].copy()\n",
    "        merged_codes = []\n",
    "        merged_ids = []\n",
    "        \n",
    "        for stop_to_merge in stops_to_merge:\n",
    "            merged_codes.extend(stop_to_merge['gtfs_props']['stop_code'].split(','))\n",
    "            merged_ids.extend(stop_to_merge['gtfs_props']['stop_id'].split(','))\n",
    "            \n",
    "            # Copy the first stop in the list and update the keys\n",
    "            new_stop['gtfs_props']['stop_code'] = ','.join(merged_codes)\n",
    "            new_stop['gtfs_props']['stop_id'] = ','.join(merged_ids)\n",
    "            new_stop['tags']['ref'] = ';'.join(merged_codes)\n",
    "            \n",
    "        unique_stops_merged.append(new_stop)\n",
    "        \n",
    "    if len(stops_to_merge) == 1:\n",
    "        unique_stops_merged.append(stops_to_merge[0])\n",
    "            \n",
    "print('Unique stops before merge: {}'.format(len(unique_stops)))\n",
    "print('Unique stops after merge: {}'.format(len(unique_stops_merged)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:43:37.447228Z",
     "start_time": "2019-01-19T15:43:37.250621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique_stops_merged_file = os.path.join(output_dir, 'unique_stops_merged.geojson')\n",
    "dict_to_geojson(unique_stops_merged, unique_stops_merged_file, 'geom', 'gtfs_props', 4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate GTFS routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:52:25.910213Z",
     "start_time": "2019-01-19T15:52:25.899356Z"
    }
   },
   "outputs": [],
   "source": [
    "routes_data = gtfs_data['routes']['data']\n",
    "stop_times_data = gtfs_data['stop_times']['data']\n",
    "trips_data = gtfs_data['trips']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:53:01.353774Z",
     "start_time": "2019-01-19T15:53:01.333933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find all trips for a route\n",
    "route_trips = defaultdict(set)\n",
    "\n",
    "for trip in trips_data:\n",
    "    route_trips[trip['route_id']].add(trip['trip_id'])\n",
    "    \n",
    "route_trips = dict(route_trips)\n",
    "    \n",
    "for route_id, trip_ids_set in route_trips.items():\n",
    "    route_trips[route_id] = list(trip_ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:53:18.237451Z",
     "start_time": "2019-01-19T15:53:17.348216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abf91bafc7d48809874017488d25acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=667585), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stops per trip\n",
    "stops_counter = Counter()\n",
    "\n",
    "for stop_time in tqdm_notebook(stop_times_data):\n",
    "    stops_counter[stop_time['trip_id']] += 1\n",
    "\n",
    "stops_counter = dict(stops_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:53:52.000941Z",
     "start_time": "2019-01-19T15:53:48.835084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8467a8687c54824b11ca1fb134c171a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the longest trip per route\n",
    "longest_route_trips = []\n",
    "\n",
    "for route_id, trip_ids in tqdm_notebook(route_trips.items()):\n",
    "    trips = []\n",
    "    \n",
    "    for trip_id, stop_count in stops_counter.items():\n",
    "        if trip_id in trip_ids:\n",
    "            trips.append((trip_id, stop_count))\n",
    "            \n",
    "    trips.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    longest_route_trips.append({\n",
    "        \"route_id\": route_id,\n",
    "        \"trip_id\": trips[0][0],\n",
    "        \"stops_count\": trips[0][1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T15:54:02.753328Z",
     "start_time": "2019-01-19T15:54:02.732483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'route_id': 'JUIN1861N',\n",
       " 'stops_count': 58,\n",
       " 'trip_id': 'JUIN1861N1D6516200517'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_route_trips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T16:11:28.665466Z",
     "start_time": "2019-01-19T16:11:04.420168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86596f18c8b74ae2b3d370adb681b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the stop ids to the longest route\n",
    "for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "    trip_id = longest_trip['trip_id']\n",
    "    stop_ids = []\n",
    "    \n",
    "    for stop_time in stop_times_data:\n",
    "        if stop_time['trip_id'] == trip_id:\n",
    "#             stop_ids.append((stop_time['stop_id'], int(stop_time['stop_sequence'])))\n",
    "            stop_ids.append({\n",
    "                \"gtfs_id\": stop_time['stop_id'],\n",
    "                \"sequence\": int(stop_time['stop_sequence'])\n",
    "            })\n",
    "            \n",
    "#     stop_ids.sort(key=itemgetter(1))\n",
    "    stop_ids.sort(key=itemgetter('sequence'))\n",
    "    longest_trip['gtfs_stop_ids'] = stop_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T16:18:22.226480Z",
     "start_time": "2019-01-19T16:18:22.212046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gtfs_stop_ids': [{'gtfs_id': 'JUIN18CP48061', 'sequence': 1},\n",
       "  {'gtfs_id': 'JUIN1843343', 'sequence': 2},\n",
       "  {'gtfs_id': 'JUIN1843146', 'sequence': 3},\n",
       "  {'gtfs_id': 'JUIN18CP41957', 'sequence': 4},\n",
       "  {'gtfs_id': 'JUIN1841952', 'sequence': 5},\n",
       "  {'gtfs_id': 'JUIN1842833', 'sequence': 6},\n",
       "  {'gtfs_id': 'JUIN1843380', 'sequence': 7},\n",
       "  {'gtfs_id': 'JUIN1843381', 'sequence': 8},\n",
       "  {'gtfs_id': 'JUIN1843980', 'sequence': 9},\n",
       "  {'gtfs_id': 'JUIN1846530', 'sequence': 10},\n",
       "  {'gtfs_id': 'JUIN1843382', 'sequence': 11},\n",
       "  {'gtfs_id': 'JUIN1843383', 'sequence': 12},\n",
       "  {'gtfs_id': 'JUIN18CP44061', 'sequence': 13},\n",
       "  {'gtfs_id': 'JUIN1843295', 'sequence': 14},\n",
       "  {'gtfs_id': 'JUIN1841510', 'sequence': 15},\n",
       "  {'gtfs_id': 'JUIN1841770', 'sequence': 16},\n",
       "  {'gtfs_id': 'JUIN1843405', 'sequence': 17},\n",
       "  {'gtfs_id': 'JUIN1841772', 'sequence': 18},\n",
       "  {'gtfs_id': 'JUIN1841296', 'sequence': 19},\n",
       "  {'gtfs_id': 'JUIN1841605', 'sequence': 20},\n",
       "  {'gtfs_id': 'JUIN1841603', 'sequence': 21},\n",
       "  {'gtfs_id': 'JUIN1846535', 'sequence': 22},\n",
       "  {'gtfs_id': 'JUIN1845027', 'sequence': 23},\n",
       "  {'gtfs_id': 'JUIN1841608', 'sequence': 24},\n",
       "  {'gtfs_id': 'JUIN1846424', 'sequence': 25},\n",
       "  {'gtfs_id': 'JUIN1846307', 'sequence': 26},\n",
       "  {'gtfs_id': 'JUIN18CP41446', 'sequence': 27},\n",
       "  {'gtfs_id': 'JUIN1841448', 'sequence': 28},\n",
       "  {'gtfs_id': 'JUIN1841450', 'sequence': 29},\n",
       "  {'gtfs_id': 'JUIN1846326', 'sequence': 30},\n",
       "  {'gtfs_id': 'JUIN1841678', 'sequence': 31},\n",
       "  {'gtfs_id': 'JUIN1841676', 'sequence': 32},\n",
       "  {'gtfs_id': 'JUIN1841674', 'sequence': 33},\n",
       "  {'gtfs_id': 'JUIN1841672', 'sequence': 34},\n",
       "  {'gtfs_id': 'JUIN1841670', 'sequence': 35},\n",
       "  {'gtfs_id': 'JUIN1841685', 'sequence': 36},\n",
       "  {'gtfs_id': 'JUIN1841682', 'sequence': 37},\n",
       "  {'gtfs_id': 'JUIN1841632', 'sequence': 38},\n",
       "  {'gtfs_id': 'JUIN1841630', 'sequence': 39},\n",
       "  {'gtfs_id': 'JUIN1841306', 'sequence': 40},\n",
       "  {'gtfs_id': 'JUIN1841304', 'sequence': 41},\n",
       "  {'gtfs_id': 'JUIN1841309', 'sequence': 42},\n",
       "  {'gtfs_id': 'JUIN1841311', 'sequence': 43},\n",
       "  {'gtfs_id': 'JUIN1841683', 'sequence': 44},\n",
       "  {'gtfs_id': 'JUIN18CP41681', 'sequence': 45},\n",
       "  {'gtfs_id': 'JUIN1842431', 'sequence': 46},\n",
       "  {'gtfs_id': 'JUIN1842434', 'sequence': 47},\n",
       "  {'gtfs_id': 'JUIN1842436', 'sequence': 48},\n",
       "  {'gtfs_id': 'JUIN1841472', 'sequence': 49},\n",
       "  {'gtfs_id': 'JUIN1841474', 'sequence': 50},\n",
       "  {'gtfs_id': 'JUIN1841759', 'sequence': 51},\n",
       "  {'gtfs_id': 'JUIN1841761', 'sequence': 52},\n",
       "  {'gtfs_id': 'JUIN1841763', 'sequence': 53},\n",
       "  {'gtfs_id': 'JUIN1841765', 'sequence': 54},\n",
       "  {'gtfs_id': 'JUIN1841767', 'sequence': 55},\n",
       "  {'gtfs_id': 'JUIN1841777', 'sequence': 56},\n",
       "  {'gtfs_id': 'JUIN1841779', 'sequence': 57},\n",
       "  {'gtfs_id': 'JUIN18CP43268', 'sequence': 58}],\n",
       " 'route_id': 'JUIN1861N',\n",
       " 'stops_count': 58,\n",
       " 'trip_id': 'JUIN1861N1D6516200517'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_route_trips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T17:58:43.283993Z",
     "start_time": "2019-01-19T17:57:59.412241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8f363f233844178862adc8063dba78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Map the GTFS stops to the merged unique stops\n",
    "for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "    for gtfs_stop in longest_trip['gtfs_stop_ids']:\n",
    "        for unique_stop in unique_stops_merged:\n",
    "            unique_stop_ids = unique_stop['gtfs_props']['stop_id'].split(',')\n",
    "            osm_id = unique_stop['props']['id']\n",
    "            name = unique_stop['tags']['name']\n",
    "            if gtfs_stop['gtfs_id'] in unique_stop_ids:\n",
    "                gtfs_stop.update({\n",
    "                    \"osm_id\": osm_id,\n",
    "                    \"name\": name\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T17:58:46.388097Z",
     "start_time": "2019-01-19T17:58:46.367157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gtfs_stop_ids': [{'gtfs_id': 'JUIN18CP48061',\n",
       "   'name': 'Métro Montmorency Quai:8',\n",
       "   'osm_id': '-47',\n",
       "   'sequence': 1},\n",
       "  {'gtfs_id': 'JUIN1843343',\n",
       "   'name': \"Du Souvenir / De L'avenir\",\n",
       "   'osm_id': '-42',\n",
       "   'sequence': 2},\n",
       "  {'gtfs_id': 'JUIN1843146',\n",
       "   'name': 'Du Souvenir / Le Corbusier',\n",
       "   'osm_id': '-1636',\n",
       "   'sequence': 3},\n",
       "  {'gtfs_id': 'JUIN18CP41957',\n",
       "   'name': 'Le Corbusier / Du Souvenir - Centre Laval',\n",
       "   'osm_id': '-2022',\n",
       "   'sequence': 4},\n",
       "  {'gtfs_id': 'JUIN1841952',\n",
       "   'name': 'Le Corbusier / Saint-Martin',\n",
       "   'osm_id': '-612',\n",
       "   'sequence': 5},\n",
       "  {'gtfs_id': 'JUIN1842833',\n",
       "   'name': 'Saint-Martin / Le Corbusier',\n",
       "   'osm_id': '-2407',\n",
       "   'sequence': 6},\n",
       "  {'gtfs_id': 'JUIN1843380',\n",
       "   'name': 'Pierre-Péladeau / Saint-Martin',\n",
       "   'osm_id': '-2672',\n",
       "   'sequence': 7},\n",
       "  {'gtfs_id': 'JUIN1843381',\n",
       "   'name': 'Pierre-Péladeau / Cinéma Colossus',\n",
       "   'osm_id': '-1667',\n",
       "   'sequence': 8},\n",
       "  {'gtfs_id': 'JUIN1843980',\n",
       "   'name': 'Pierre-Péladeau / Terry-Fox',\n",
       "   'osm_id': '-383',\n",
       "   'sequence': 9},\n",
       "  {'gtfs_id': 'JUIN1846530',\n",
       "   'name': 'Du Cosmodôme / Pierre-Péladeau',\n",
       "   'osm_id': '-2514',\n",
       "   'sequence': 10},\n",
       "  {'gtfs_id': 'JUIN1843382',\n",
       "   'name': 'Terry-Fox / Du Cosmodôme',\n",
       "   'osm_id': '-1352',\n",
       "   'sequence': 11},\n",
       "  {'gtfs_id': 'JUIN1843383',\n",
       "   'name': 'Terry-Fox / édouard-Montpetit',\n",
       "   'osm_id': '-1005',\n",
       "   'sequence': 12},\n",
       "  {'gtfs_id': 'JUIN18CP44061',\n",
       "   'name': 'Terminus Le Carrefour Quai:3',\n",
       "   'osm_id': '-1639',\n",
       "   'sequence': 13},\n",
       "  {'gtfs_id': 'JUIN1843295',\n",
       "   'name': 'Le Carrefour / Face Au Sears',\n",
       "   'osm_id': '-943',\n",
       "   'sequence': 14},\n",
       "  {'gtfs_id': 'JUIN1841510',\n",
       "   'name': 'Daniel-Johnson / Face Au 2540',\n",
       "   'osm_id': '-1190',\n",
       "   'sequence': 15},\n",
       "  {'gtfs_id': 'JUIN1841770',\n",
       "   'name': 'Jean-Béraud / Daniel-Johnson',\n",
       "   'osm_id': '-1932',\n",
       "   'sequence': 16},\n",
       "  {'gtfs_id': 'JUIN1843405',\n",
       "   'name': 'Jean-Béraud / Face Au 3285',\n",
       "   'osm_id': '-194',\n",
       "   'sequence': 17},\n",
       "  {'gtfs_id': 'JUIN1841772',\n",
       "   'name': 'Jean-Béraud / Chomedey',\n",
       "   'osm_id': '-224',\n",
       "   'sequence': 18},\n",
       "  {'gtfs_id': 'JUIN1841296',\n",
       "   'name': 'Chomedey / Face Au 2911',\n",
       "   'osm_id': '-225',\n",
       "   'sequence': 19},\n",
       "  {'gtfs_id': 'JUIN1841605',\n",
       "   'name': 'Saint-Elzéar / Chomedey',\n",
       "   'osm_id': '-2411',\n",
       "   'sequence': 20},\n",
       "  {'gtfs_id': 'JUIN1841603',\n",
       "   'name': 'Saint-Elzéar / Face Au Marché 440',\n",
       "   'osm_id': '-2653',\n",
       "   'sequence': 21},\n",
       "  {'gtfs_id': 'JUIN1846535',\n",
       "   'name': 'Saint-Elzéar / Face Au 3665',\n",
       "   'osm_id': '-67',\n",
       "   'sequence': 22},\n",
       "  {'gtfs_id': 'JUIN1845027',\n",
       "   'name': 'Saint-Elzéar / Joachim-Du Bellay',\n",
       "   'osm_id': '-2559',\n",
       "   'sequence': 23},\n",
       "  {'gtfs_id': 'JUIN1841608',\n",
       "   'name': 'Saint-Elzéar / Curé-Labelle',\n",
       "   'osm_id': '-1114',\n",
       "   'sequence': 24},\n",
       "  {'gtfs_id': 'JUIN1846424',\n",
       "   'name': 'Curé-Labelle / Simone-De-Beauvoir',\n",
       "   'osm_id': '-914',\n",
       "   'sequence': 25},\n",
       "  {'gtfs_id': 'JUIN1846307',\n",
       "   'name': 'Curé-Labelle / Face Au Funtropolis',\n",
       "   'osm_id': '-2483',\n",
       "   'sequence': 26},\n",
       "  {'gtfs_id': 'JUIN18CP41446',\n",
       "   'name': 'Curé-Labelle / édith',\n",
       "   'osm_id': '-2749',\n",
       "   'sequence': 27},\n",
       "  {'gtfs_id': 'JUIN1841448',\n",
       "   'name': 'Curé-Labelle / éricka',\n",
       "   'osm_id': '-1752',\n",
       "   'sequence': 28},\n",
       "  {'gtfs_id': 'JUIN1841450',\n",
       "   'name': 'Curé-Labelle / Dagenais',\n",
       "   'osm_id': '-1993',\n",
       "   'sequence': 29},\n",
       "  {'gtfs_id': 'JUIN1846326',\n",
       "   'name': 'Gabriel / Gilles',\n",
       "   'osm_id': '-369',\n",
       "   'sequence': 30},\n",
       "  {'gtfs_id': 'JUIN1841678',\n",
       "   'name': 'Gilles / Glenn',\n",
       "   'osm_id': '-1407',\n",
       "   'sequence': 31},\n",
       "  {'gtfs_id': 'JUIN1841676',\n",
       "   'name': 'Gilles / Christiane',\n",
       "   'osm_id': '-1921',\n",
       "   'sequence': 32},\n",
       "  {'gtfs_id': 'JUIN1841674',\n",
       "   'name': 'Gilles / Godefroy',\n",
       "   'osm_id': '-2737',\n",
       "   'sequence': 33},\n",
       "  {'gtfs_id': 'JUIN1841672',\n",
       "   'name': 'Gilles / Camille',\n",
       "   'osm_id': '-1802',\n",
       "   'sequence': 34},\n",
       "  {'gtfs_id': 'JUIN1841670',\n",
       "   'name': 'Gilles / Colomban',\n",
       "   'osm_id': '-1677',\n",
       "   'sequence': 35},\n",
       "  {'gtfs_id': 'JUIN1841685',\n",
       "   'name': 'Gilles / Carmina',\n",
       "   'osm_id': '-1747',\n",
       "   'sequence': 36},\n",
       "  {'gtfs_id': 'JUIN1841682',\n",
       "   'name': 'Gilles / Fleury',\n",
       "   'osm_id': '-112',\n",
       "   'sequence': 37},\n",
       "  {'gtfs_id': 'JUIN1841632',\n",
       "   'name': 'Fleury / Chantal',\n",
       "   'osm_id': '-2477',\n",
       "   'sequence': 38},\n",
       "  {'gtfs_id': 'JUIN1841630',\n",
       "   'name': 'Fleury / Christiane',\n",
       "   'osm_id': '-363',\n",
       "   'sequence': 39},\n",
       "  {'gtfs_id': 'JUIN1841306',\n",
       "   'name': 'Christiane / Fabiola',\n",
       "   'osm_id': '-1319',\n",
       "   'sequence': 40},\n",
       "  {'gtfs_id': 'JUIN1841304',\n",
       "   'name': 'Christiane / Fridolin',\n",
       "   'osm_id': '-1072',\n",
       "   'sequence': 41},\n",
       "  {'gtfs_id': 'JUIN1841309',\n",
       "   'name': 'Christiane / Bernadette',\n",
       "   'osm_id': '-525',\n",
       "   'sequence': 42},\n",
       "  {'gtfs_id': 'JUIN1841311',\n",
       "   'name': 'Christiane / Gilles',\n",
       "   'osm_id': '-2664',\n",
       "   'sequence': 43},\n",
       "  {'gtfs_id': 'JUIN1841683',\n",
       "   'name': 'Gilles / Basile',\n",
       "   'osm_id': '-1338',\n",
       "   'sequence': 44},\n",
       "  {'gtfs_id': 'JUIN18CP41681',\n",
       "   'name': 'Gilles / Montée Montrougeau',\n",
       "   'osm_id': '-141',\n",
       "   'sequence': 45},\n",
       "  {'gtfs_id': 'JUIN1842431',\n",
       "   'name': 'Montée Montrougeau / Marian',\n",
       "   'osm_id': '-1815',\n",
       "   'sequence': 46},\n",
       "  {'gtfs_id': 'JUIN1842434',\n",
       "   'name': 'Montée Montrougeau / Anik',\n",
       "   'osm_id': '-2272',\n",
       "   'sequence': 47},\n",
       "  {'gtfs_id': 'JUIN1842436',\n",
       "   'name': 'Montée Montrougeau / Dagenais',\n",
       "   'osm_id': '-2153',\n",
       "   'sequence': 48},\n",
       "  {'gtfs_id': 'JUIN1841472',\n",
       "   'name': 'Dagenais / Luce',\n",
       "   'osm_id': '-578',\n",
       "   'sequence': 49},\n",
       "  {'gtfs_id': 'JUIN1841474',\n",
       "   'name': 'Dagenais / Lisane',\n",
       "   'osm_id': '-1153',\n",
       "   'sequence': 50},\n",
       "  {'gtfs_id': 'JUIN1841759',\n",
       "   'name': 'Jacques / Julie',\n",
       "   'osm_id': '-2233',\n",
       "   'sequence': 51},\n",
       "  {'gtfs_id': 'JUIN1841761',\n",
       "   'name': 'Jacques / Jovette',\n",
       "   'osm_id': '-123',\n",
       "   'sequence': 52},\n",
       "  {'gtfs_id': 'JUIN1841763',\n",
       "   'name': 'Jacques / Isabelle',\n",
       "   'osm_id': '-1557',\n",
       "   'sequence': 53},\n",
       "  {'gtfs_id': 'JUIN1841765',\n",
       "   'name': 'Jacques / Julio',\n",
       "   'osm_id': '-948',\n",
       "   'sequence': 54},\n",
       "  {'gtfs_id': 'JUIN1841767',\n",
       "   'name': 'Jacques / Jeannette',\n",
       "   'osm_id': '-679',\n",
       "   'sequence': 55},\n",
       "  {'gtfs_id': 'JUIN1841777',\n",
       "   'name': 'Jeannette / Jeannette',\n",
       "   'osm_id': '-129',\n",
       "   'sequence': 56},\n",
       "  {'gtfs_id': 'JUIN1841779',\n",
       "   'name': 'Jeannette / Josué',\n",
       "   'osm_id': '-83',\n",
       "   'sequence': 57},\n",
       "  {'gtfs_id': 'JUIN18CP43268',\n",
       "   'name': 'Édith / Face à Hydro Québec',\n",
       "   'osm_id': '-2295',\n",
       "   'sequence': 58}],\n",
       " 'route_id': 'JUIN1861N',\n",
       " 'stops_count': 58,\n",
       " 'tags': {'from': 'Métro Montmorency Quai:8',\n",
       "  'name': 'Direction Fabreville',\n",
       "  'network': 'STL',\n",
       "  'operator': 'STL',\n",
       "  'public_transport:version': 2,\n",
       "  'ref': 'Fabreville',\n",
       "  'round_trip': 'no',\n",
       "  'route': 'bus',\n",
       "  'to': 'Édith / Face à Hydro Québec',\n",
       "  'type': 'route'},\n",
       " 'trip_id': 'JUIN1861N1D6516200517'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_route_trips[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the route names and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T18:10:40.366278Z",
     "start_time": "2019-01-19T18:10:40.302059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f6254572c249f8b951efb7e2603a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Métro Montmorency Quai:8\n",
      "1 Terminus Le Carrefour Quai:10\n",
      "2 Métro Cartier Quai:4\n",
      "3 Montgolfier / Notre-Dame\n",
      "4 Terminus Contant\n",
      "5 Chartrand / Déry\n",
      "6 Métro Montmorency Quai:7\n",
      "7 Métro Cartier Quai:4\n",
      "8 Métro Montmorency Quai:7\n",
      "9 Métro Cartier Quai:4\n",
      "10 Terminus Henri-Bourassa\n",
      "11 Métro Montmorency Quai:9\n",
      "12 Métro Cartier\n",
      "13 Juge-Desnoyers / Face Au 520\n",
      "14 Terminus 9e Avenue\n",
      "15 Chartrand / Déry\n",
      "16 Gare Vimont\n",
      "17 Chartrand / Déry\n",
      "18 Terminus Contant\n",
      "19 Métro Cartier Quai:4\n",
      "20 Métro Montmorency Quai:8\n",
      "21 Métro Montmorency Quai:8\n",
      "22 Terminus Henri-Bourassa\n",
      "23 Métro Montmorency Quai:7\n",
      "24 Terminus Bienville\n",
      "25 Gare Sainte-Dorothée\n",
      "26 Métro Montmorency Quai:6\n",
      "27 Terminus Cléroux\n",
      "28 Métro Montmorency Quai:8\n",
      "29 Métro Montmorency Quai:7\n",
      "30 Métro Cartier Quai:9\n",
      "31 Terminus Henri-Bourassa\n",
      "32 Terminus Contant\n",
      "33 Métro Cartier\n",
      "34 Thibault / Des Laurentides\n",
      "35 Terminus Bienville\n",
      "36 Arthur-Sauvé / Prévert\n",
      "37 Carole / Des Tulipes\n",
      "38 Terminus Bienville\n",
      "39 Métro Montmorency Quai:9\n",
      "40 Carole / Des Tulipes\n",
      "41 Métro Cartier Quai:4\n",
      "42 Justin / Face à Hydro Québec\n",
      "43 Métro Montmorency Quai:7\n",
      "44 Gare Sainte-Rose\n",
      "45 Métro Cartier\n",
      "46 Métro Cartier Quai:5\n",
      "47 Gare Sainte-Rose\n",
      "48 Montée Saint-François / Face Au Pénitencier\n",
      "49 Terminus Contant\n",
      "50 Terminus Le Carrefour Quai:8\n",
      "51 Métro Cartier Quai:9\n",
      "52 Gare Sainte-Dorothée\n",
      "53 Métro Montmorency Quai:8\n",
      "54 Terminus Henri-Bourassa\n",
      "55 Montgolfier / Notre-Dame\n",
      "56 Métro Cartier Quai:6\n",
      "57 Saint-Martin / Des Pivoines\n",
      "58 Métro Côte-Vertu\n",
      "59 Sainte-Rose / Face Au 3261\n",
      "60 Métro Cartier Quai:9\n",
      "61 Boucle Montgolfier\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e0ccef0c9346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(route_stops[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfirst_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroute_stops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlast_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroute_stops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "for i, longest_route in enumerate(tqdm_notebook(longest_route_trips)):\n",
    "    route_id = longest_route['route_id']\n",
    "    route_stops = longest_route['gtfs_stop_ids']\n",
    "    \n",
    "#     print(route_stops[0])\n",
    "\n",
    "    first_stop = route_stops[0]['name']\n",
    "    print(i, first_stop)\n",
    "    last_stop = route_stops[-1]['name']\n",
    "\n",
    "    loop_route = 'no'\n",
    "\n",
    "    if first_stop == last_stop:\n",
    "        loop_route = 'yes'\n",
    "\n",
    "    for route in routes_data:\n",
    "        if route_id == route['route_id']:\n",
    "            longest_route.update({\n",
    "                \"tags\": {\n",
    "                    \"name\": route['route_long_name'],\n",
    "                    \"ref\": route[\"route_headsign\"],\n",
    "                    \"type\": \"route\",\n",
    "                    \"route\": \"bus\",\n",
    "                    \"network\": \"STL\",\n",
    "                    \"operator\": \"STL\",\n",
    "                    \"from\": first_stop,\n",
    "                    \"to\": last_stop,\n",
    "                    \"round_trip\": loop_route,\n",
    "                    \"public_transport:version\": 2\n",
    "                }\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:35.199585Z",
     "start_time": "2019-01-13T16:27:34.931646Z"
    }
   },
   "outputs": [],
   "source": [
    "root = ET.Element(\"osm\")\n",
    "root.set('version', '0.6')\n",
    "\n",
    "min_lon, max_lon, min_lat, max_lat = multi_point.GetEnvelope()\n",
    "\n",
    "bounds = ET.SubElement(root, 'bounds')\n",
    "bounds.set('minlat', str(min_lat))\n",
    "bounds.set('minlon', str(min_lon))\n",
    "bounds.set('maxlat', str(max_lat))\n",
    "bounds.set('maxlon', str(max_lon))\n",
    "\n",
    "for stop in unique_stops_osm:\n",
    "    node = ET.SubElement(root, 'node')\n",
    "    node.set('version', '1')\n",
    "    \n",
    "    for key, value in stop.items():\n",
    "        if key == 'tags':\n",
    "            for k, v in stop['tags'].items():\n",
    "                tag = ET.SubElement(node, 'tag')\n",
    "                tag.set('k', str(k))\n",
    "                tag.set('v', str(v))\n",
    "        else:\n",
    "            node.set(key, value)\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"gtfs_laval.xml\", encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:36.216820Z",
     "start_time": "2019-01-13T16:27:36.210091Z"
    }
   },
   "outputs": [],
   "source": [
    "# unique_stops_osm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:37.053172Z",
     "start_time": "2019-01-13T16:27:37.042226Z"
    }
   },
   "outputs": [],
   "source": [
    "# route_results = api.query(service_route_tmpl.format(region_ids['Laval']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:37.520601Z",
     "start_time": "2019-01-13T16:27:37.507993Z"
    }
   },
   "outputs": [],
   "source": [
    "# route_results.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:37.902259Z",
     "start_time": "2019-01-13T16:27:37.896478Z"
    }
   },
   "outputs": [],
   "source": [
    "# for relation in route_results.relations:\n",
    "#     print(relation.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:38.283528Z",
     "start_time": "2019-01-13T16:27:38.275708Z"
    }
   },
   "outputs": [],
   "source": [
    "# gtfs_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:39.350307Z",
     "start_time": "2019-01-13T16:27:39.346807Z"
    }
   },
   "outputs": [],
   "source": [
    "# routes_data = gtfs_data['routes']['data']\n",
    "# stop_times_data = gtfs_data['stop_times']['data']\n",
    "# trips_data = gtfs_data['trips']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:40.204665Z",
     "start_time": "2019-01-13T16:27:40.146400Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Find all trips for a route\n",
    "# route_trips = defaultdict(set)\n",
    "\n",
    "# for trip in trips_data:\n",
    "#     route_trips[trip['route_id']].add(trip['trip_id'])\n",
    "    \n",
    "# route_trips = dict(route_trips)\n",
    "    \n",
    "# for route_id, trip_ids_set in route_trips.items():\n",
    "#     route_trips[route_id] = list(trip_ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:42.082686Z",
     "start_time": "2019-01-13T16:27:41.106981Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Count the number of stops per trip\n",
    "# stops_counter = Counter()\n",
    "\n",
    "# for stop_time in tqdm_notebook(stop_times_data):\n",
    "#     stops_counter[stop_time['trip_id']] += 1\n",
    "\n",
    "# stops_counter = dict(stops_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:27:45.902054Z",
     "start_time": "2019-01-13T16:27:42.670151Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Find the longest trip per route\n",
    "# longest_route_trips = []\n",
    "\n",
    "# for route_id, trip_ids in tqdm_notebook(route_trips.items()):\n",
    "#     trips = []\n",
    "    \n",
    "#     for trip_id, stop_count in stops_counter.items():\n",
    "#         if trip_id in trip_ids:\n",
    "#             trips.append((trip_id, stop_count))\n",
    "            \n",
    "#     trips.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "#     longest_route_trips.append({\n",
    "#         \"route_id\": route_id,\n",
    "#         \"trip_id\": trips[0][0],\n",
    "#         \"stops_count\": trips[0][1]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:28:22.623051Z",
     "start_time": "2019-01-13T16:27:46.515660Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Add the stop ids to the longest route\n",
    "# for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "#     trip_id = longest_trip['trip_id']\n",
    "#     stop_ids = []\n",
    "    \n",
    "#     for stop_time in stop_times_data:\n",
    "#         if stop_time['trip_id'] == trip_id:\n",
    "#             stop_ids.append((stop_time['stop_id'], int(stop_time['stop_sequence'])))\n",
    "            \n",
    "#     stop_ids.sort(key=itemgetter(1))\n",
    "#     longest_trip['gtfs_stop_ids'] = stop_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:29:26.151698Z",
     "start_time": "2019-01-13T16:29:14.495099Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Map the GTFS stops to the OSM stops\n",
    "# for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "#     osm_ids = []\n",
    "    \n",
    "#     for gtfs_id, sequence in longest_trip['gtfs_stop_ids']:\n",
    "#         # find the GTFS id in the map dictionary\n",
    "#         for gtfs_ids, osm_id in unique_stops_map:\n",
    "#             if int(osm_id) > 0:\n",
    "#                 print(osm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T16:30:26.236088Z",
     "start_time": "2019-01-13T16:30:25.926805Z"
    }
   },
   "outputs": [],
   "source": [
    "# for stop in unique_stops_osm:\n",
    "# #     if int(stop['id']) > 0:\n",
    "# #         print(stop['id'])\n",
    "#     print(stop['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
