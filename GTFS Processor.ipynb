{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:28.744788Z",
     "start_time": "2019-01-27T15:52:28.454602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import csv, json\n",
    "import ogr, osr\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import defaultdict, Counter\n",
    "from matplotlib import pyplot as plt, figure\n",
    "import copy\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "import overpy\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ogr.UseExceptions()\n",
    "osr.UseExceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:30.034343Z",
     "start_time": "2019-01-27T15:52:29.892255Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parent directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# zipfile\n",
    "zipfile = os.path.join(cwd, 'gtfs.zip')\n",
    "\n",
    "# Child directories\n",
    "boundaries_dir = os.path.join(cwd, 'boundaries')\n",
    "gtfs_dir = os.path.join(cwd, 'gtfs')\n",
    "output_dir = os.path.join(cwd, 'output')\n",
    "\n",
    "# Create output directory\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "# Create gtfs directory\n",
    "if os.path.exists(gtfs_dir):\n",
    "    shutil.rmtree(gtfs_dir)\n",
    "os.makedirs(gtfs_dir)\n",
    "\n",
    "# Unzip GTFS\n",
    "shutil.unpack_archive(zipfile, gtfs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:31.295583Z",
     "start_time": "2019-01-27T15:52:31.175572Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dict_to_geojson(data, out_path, geom_field, fields_key=None, epsg_id=None):\n",
    "    \n",
    "    # Create path\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "        \n",
    "    # Get GeoJSON driver\n",
    "    driver = ogr.GetDriverByName('GeoJSON')\n",
    "    \n",
    "    ds = driver.CreateDataSource(out_path)\n",
    "    \n",
    "    spatial_ref = osr.SpatialReference()\n",
    "    if epsg_id:\n",
    "        spatial_ref.ImportFromEPSG(4326)\n",
    "    else:\n",
    "        spatial_ref.ImportFromEPSG(epsg_id)\n",
    "        \n",
    "    # Get geom type\n",
    "    geom_type = data[0][geom_field].GetGeometryType()\n",
    "    \n",
    "    layer = ds.CreateLayer(out_path, geom_type=geom_type, srs=spatial_ref)\n",
    "    \n",
    "    # Create the fields\n",
    "    if fields_key:\n",
    "        field_names = data[0][fields_key].keys()\n",
    "        for i, field_name in enumerate(field_names): \n",
    "            layer.CreateField(ogr.FieldDefn(field_name, ogr.OFTString))\n",
    "    \n",
    "    layer_defn = layer.GetLayerDefn()\n",
    "    \n",
    "    for item in data:\n",
    "        feature = ogr.Feature(layer_defn)\n",
    "        \n",
    "        if fields_key:\n",
    "            for field_name in field_names:\n",
    "                feature.SetField(field_name, item[fields_key][field_name])\n",
    "        \n",
    "        feature.SetGeometry(item[geom_field])\n",
    "        \n",
    "        layer.CreateFeature(feature)\n",
    "        \n",
    "def objects_to_xml(path, bounds=None, nodes=None, ways=None, relations=None):\n",
    "    root = ET.Element(\"osm\")\n",
    "    pass\n",
    "\n",
    "def reproject_geometry(geom, in_epsg, out_epsg, return_wkt=False):\n",
    "    import ogr, osr\n",
    "\n",
    "    source = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(in_epsg)\n",
    "\n",
    "    target = osr.SpatialReference()\n",
    "    target.ImportFromEPSG(out_epsg)\n",
    "\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "    geom.Transform(transform)\n",
    "\n",
    "    if return_wkt:\n",
    "        return geom.ExportToWkt()\n",
    "    else:\n",
    "        return geom\n",
    "    \n",
    "def write_geometry_to_geojson(geom, out_path):\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "    \n",
    "    driver = ogr.GetDriverByName('GeoJSON')\n",
    "    ds = driver.CreateDataSource(out_path)\n",
    "    \n",
    "    geom_type = geom.GetGeometryType()\n",
    "    \n",
    "    layer = ds.CreateLayer(out_path, geom_type=geom_type)\n",
    "    layer_defn = layer.GetLayerDefn()\n",
    "    \n",
    "    feature = ogr.Feature(layer_defn)\n",
    "    feature.SetGeometry(geom)\n",
    "    layer.CreateFeature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-13T08:18:14.967932Z",
     "start_time": "2019-01-13T08:18:14.957921Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Overpy Query Templates\n",
    "\n",
    "*Overpass doesn't allow Geocoding like Turbo Overpass does so I've gathered the city relation ids beforehand to use directly with overpass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:32.508092Z",
     "start_time": "2019-01-27T15:52:32.499150Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "api = overpy.Overpass()\n",
    "\n",
    "relation_to_area_factor = 3600000000\n",
    "\n",
    "region_ids = {\n",
    "    \"Laval\": 3532125 + relation_to_area_factor,\n",
    "    \"Montreal\": 1571328 + relation_to_area_factor\n",
    "}\n",
    "\n",
    "bus_stop_tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "    node[\"highway\"=\"bus_stop\"](area.searchArea);\n",
    "    way[\"highway\"=\"platform\"](area.searchArea);\n",
    "\n",
    "    node[\"public_transport\"=\"platform\"][\"bus\"=\"yes\"](area.searchArea);\n",
    "    node[\"public_transport\"=\"stop_position\"][\"bus\"=\"yes\"](area.searchArea);\n",
    "    \n",
    "    way[\"amenity\"=\"shelter\"](area.searchArea);\n",
    "    node[\"amenity\"=\"shelter\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\"\n",
    "\n",
    "service_route_tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "    relation[\"type\"=\"route\"][\"route\"=\"bus\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\"\n",
    "\n",
    "master_route_tmpl = \"\"\"\n",
    "    area({})->.searchArea;\n",
    "    (\n",
    "    relation[\"type\"=\"master_route\"][\"route_master\"=\"bus\"](area.searchArea);\n",
    "    );\n",
    "    out body;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Boundaries into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:34.965511Z",
     "start_time": "2019-01-27T15:52:34.939170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211367975181487fa462b81236b559c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "boundaries = {}\n",
    "\n",
    "boundary_files = os.listdir(boundaries_dir)\n",
    "\n",
    "for boundary_file in tqdm_notebook(boundary_files):\n",
    "    path = os.path.join(boundaries_dir, boundary_file)\n",
    "    city = boundary_file[:-4]\n",
    "    \n",
    "    with open(path) as f:\n",
    "        geom = ogr.CreateGeometryFromWkt(f.read())\n",
    "        boundaries[city] = geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get existing data from OSM using OverPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get existing stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:57.066277Z",
     "start_time": "2019-01-27T15:52:37.004658Z"
    }
   },
   "outputs": [],
   "source": [
    "existing_stops = []\n",
    "\n",
    "stops_result_laval = api.query(bus_stop_tmpl.format(region_ids['Laval']))\n",
    "stops_result_montreal = api.query(bus_stop_tmpl.format(region_ids['Montreal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:52:57.098336Z",
     "start_time": "2019-01-27T15:52:57.082935Z"
    }
   },
   "outputs": [],
   "source": [
    "for node in stops_result_laval.nodes:\n",
    "    existing_stop = {\n",
    "        'id': node.id,\n",
    "        'lat': node.lat,\n",
    "        'lon': node.lon,\n",
    "        'tags': node.tags,\n",
    "        'city': 'Laval'\n",
    "    }\n",
    "    existing_stops.append(existing_stop)\n",
    "    \n",
    "for node in stops_result_montreal.nodes:\n",
    "    existing_stop = {\n",
    "        'id': node.id,\n",
    "        'lat': node.lat,\n",
    "        'lon': node.lon,\n",
    "        'tags': node.tags,\n",
    "        'city': 'Montreal'\n",
    "    }\n",
    "    existing_stops.append(existing_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get existing routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:06:06.419810Z",
     "start_time": "2019-01-27T17:06:02.987643Z"
    }
   },
   "outputs": [],
   "source": [
    "existing_routes = []\n",
    "existing_route_masters = []\n",
    "\n",
    "routes_result_laval = api.query(service_route_tmpl.format(region_ids['Laval']))\n",
    "route_master_result_laval = api.query(master_route_tmpl.format(region_ids['Laval']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:06:11.874466Z",
     "start_time": "2019-01-27T17:06:11.871218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'way'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_result_laval.relations[0].members[0]._type_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:07:54.279888Z",
     "start_time": "2019-01-27T17:07:54.276113Z"
    }
   },
   "outputs": [],
   "source": [
    "for relation in route_master_result_laval.relations:\n",
    "#     if hasattr(relation.tags, 'operator'):\n",
    "#         print(relation.tags.operator)\n",
    "#     if hasattr(relation.tags, 'network'):\n",
    "#         print(relation.tags.network)\n",
    "        \n",
    "    print(relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GTFS text files to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:54:06.671263Z",
     "start_time": "2019-01-27T15:54:03.571918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f6457f035945779c595863e60342be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gtfs_data = {}\n",
    "\n",
    "filenames = os.listdir(gtfs_dir)\n",
    "\n",
    "for filename in tqdm_notebook(filenames):\n",
    "    table_name = filename[:-4]\n",
    "    path = os.path.join(gtfs_dir, filename)\n",
    "    gtfs_data[table_name] = {\n",
    "        \"path\": path,\n",
    "    }\n",
    "\n",
    "    with open(path, encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        field_names = next(reader)\n",
    "        gtfs_data[table_name][\"field_names\"] = field_names\n",
    "        \n",
    "        dict_reader = csv.DictReader(csvfile, fieldnames=field_names)\n",
    "        data = [row for row in dict_reader]\n",
    "        gtfs_data[table_name][\"data\"] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the dictionary information for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:54:13.359393Z",
     "start_time": "2019-01-27T15:54:13.354507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# table: # field names\n",
      "routes: ['route_id', 'agency_id', 'route_short_name', 'route_long_name', 'route_type', 'route_url', 'route_headsign', 'route_color', 'route_text_color']\n",
      "\n",
      "stop_times: ['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence', 'pickup_type', 'drop_off_type']\n",
      "\n",
      "stops: ['stop_id', 'stop_code', 'stop_name', 'stop_lon', 'stop_lat', 'location_type', 'stop_display', 'stop_abribus']\n",
      "\n",
      "shapes: ['shape_id', 'shape_pt_lat', 'shape_pt_lon', 'shape_pt_sequence']\n",
      "\n",
      "agency: ['agency_id', 'agency_name', 'agency_url', 'agency_timezone', 'agency_lang']\n",
      "\n",
      "trips: ['route_id', 'service_id', 'trip_id', 'block_id', 'shape_id', 'trip_headsign']\n",
      "\n",
      "calendar: ['service_id', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'start_date', 'end_date']\n",
      "\n",
      "calendar_dates: ['service_id', 'date', 'exception_type']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# table: # field names')\n",
    "for key, value in gtfs_data.items():\n",
    "    print('{}: {}\\n'.format(key, value['field_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplicate the stops file\n",
    "1. Split the stop code from the name\n",
    "2. Check for name uniqueness\n",
    "3. Check for location uniqueness (with proximity tolerance - optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the stop **names** and **codes** frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:54:19.377570Z",
     "start_time": "2019-01-27T15:54:19.371424Z"
    }
   },
   "outputs": [],
   "source": [
    "# stops = gtfs_data['stops']['data']\n",
    "\n",
    "# unique_stops = []\n",
    "# stop_name_counter = Counter()\n",
    "# stop_code_counter = Counter()\n",
    "\n",
    "# for stop in tqdm_notebook(stops):\n",
    "#     real_name = stop['stop_name'].split('[')[0].strip()\n",
    "#     stop_code = stop['stop_code']\n",
    "#     stop_name_counter[real_name] += 1\n",
    "#     stop_code_counter[stop_code] += 1\n",
    "    \n",
    "# names, name_counts = zip(*stop_name_counter.items())\n",
    "# codes, code_counts = zip(*stop_code_counter.items())\n",
    "\n",
    "# bar_height = 10\n",
    "\n",
    "# plot_specs = {\n",
    "#     'names': {\n",
    "#         'positions': np.arange(len(names)),\n",
    "#         'bar_spacing': 2 * np.arange(len(names)) * bar_height,\n",
    "#         'labels': names,\n",
    "#         'values': name_counts,\n",
    "#         'title': 'Distribution of stop names'\n",
    "#     },\n",
    "#     'codes': {\n",
    "#         'positions': np.arange(len(codes)),\n",
    "#         'bar_spacing': 2 * np.arange(len(codes)) * bar_height,\n",
    "#         'labels': codes,\n",
    "#         'values': code_counts,\n",
    "#         'title': 'Distribution of stop codes'\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:54:24.855355Z",
     "start_time": "2019-01-27T15:54:24.850805Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Can't get this to work....moving on\n",
    "\n",
    "# # plt.figure(figsize=(50,30))\n",
    "# plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "# for i, (plot_name, spec) in enumerate(plot_specs.items(), 1):\n",
    "#     plt.subplot(1, 2, i)\n",
    "#     plt.barh(spec['positions'], spec['values'], height=bar_height)\n",
    "#     plt.yticks(spec['bar_spacing'], spec['labels'])\n",
    "#     plt.title(spec['title'])\n",
    "#     plt.autoscale()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T13:30:29.191793Z",
     "start_time": "2019-01-12T13:30:29.180259Z"
    }
   },
   "source": [
    "#### Create unique stops list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:58:04.920696Z",
     "start_time": "2019-01-27T15:54:30.797724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af5c47ee7b24f89a5e1678b74e0db03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2773), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stops = gtfs_data['stops']['data']\n",
    "\n",
    "# existing_count_laval = 0\n",
    "# existing_count_montreal = 0\n",
    "existing_count_total = 0\n",
    "\n",
    "# Extent\n",
    "multi_point = ogr.Geometry(ogr.wkbMultiPoint)\n",
    "\n",
    "# Dictionary to group stops by unique location\n",
    "unique_locations = defaultdict(list)\n",
    "\n",
    "# List of stops rearranged with uniqueness\n",
    "unique_stops = []\n",
    "\n",
    "# Aggregate unique locations\n",
    "for stop in stops:\n",
    "    unique_locations[(stop['stop_lon'], stop['stop_lat'])].append(stop)\n",
    "\n",
    "# Aggregate attributes using unique locations into new stop objects\n",
    "for i, (unique_location, stops) in enumerate(tqdm_notebook(unique_locations.items()), 1):\n",
    "\n",
    "    ids = list(set([stop['stop_id'] for stop in stops]))\n",
    "    codes = list(set([stop['stop_code'] for stop in stops]))\n",
    "\n",
    "    lon = float(stops[0]['stop_lon'])\n",
    "    lat = float(stops[0]['stop_lat'])\n",
    "\n",
    "    # Create point to add to MultiPoint (for JOSM extent later...)\n",
    "    point = ogr.Geometry(ogr.wkbPoint)\n",
    "    point.AddPoint(lon, lat)\n",
    "    multi_point.AddGeometry(point)\n",
    "\n",
    "    # Create the unique stop according to JOSM format\n",
    "    action = None\n",
    "\n",
    "    # While checking for:\n",
    "    # 1. What city it is ine\n",
    "    # 2. If a node with the same geometry already exists in OSM\n",
    "    # 2.1 If node is in Laval, replace the tags\n",
    "    # 2.2 If node is in Montreal, append, code and name tags\n",
    "\n",
    "#     # Get the city of the GTFS stop\n",
    "#     city = None\n",
    "#     for city_name, city_geom in boundaries.items():\n",
    "#         if point.Intersects(city_geom):\n",
    "#             city = city_name\n",
    "\n",
    "    osm_id = None\n",
    "    osm_lat = None\n",
    "    osm_lon = None\n",
    "\n",
    "    # Determine if node already exists\n",
    "    for existing_stop in existing_stops:\n",
    "        existing_point = ogr.Geometry(ogr.wkbPoint)\n",
    "        existing_point.AddPoint(\n",
    "            float(existing_stop['lon']), float(existing_stop['lat']))\n",
    "\n",
    "        if point.Equals(existing_point):\n",
    "            #             print('Equal point found')\n",
    "            existing_count_total += 1\n",
    "\n",
    "            osm_id = existing_stop['id']\n",
    "            osm_lat = existing_stop['lat']\n",
    "            osm_lon = existing_stop['lon']\n",
    "            action = 'modify'\n",
    "\n",
    "#             print(osm_id)\n",
    "        else:\n",
    "            osm_id = str(i * -1)\n",
    "            osm_lat = str(lat)\n",
    "            osm_lon = str(lon)\n",
    "\n",
    "    unique_stop = {\n",
    "        # props\n",
    "        'props': {\n",
    "            'id': osm_id,\n",
    "            'lon': osm_lon,\n",
    "            'lat': osm_lat,\n",
    "        },\n",
    "        # tags\n",
    "        'tags': {\n",
    "            'bus': 'yes',\n",
    "            'highway': 'bus_stop',\n",
    "            'name': stops[0]['stop_name'].split('[')[0].strip(),\n",
    "            'public_transport': 'platform',\n",
    "            'ref': ';'.join(codes),\n",
    "            'shelter': 'yes' if stops[0]['stop_abribus'] == '1' else 'no',\n",
    "        },\n",
    "        \"geom\": point,\n",
    "        # GTFS fields\n",
    "        \"gtfs_props\": {\n",
    "            'stop_id': ','.join(ids),\n",
    "            'stop_code': ','.join(codes),\n",
    "            'stop_name': stops[0]['stop_name'].split('[')[0].strip(),\n",
    "            'stop_lon': lon,\n",
    "            'stop_lat': lat,\n",
    "            'location_type': stops[0]['location_type'],\n",
    "            'stop_display': stops[0]['stop_display'],\n",
    "            'stop_abribus': stops[0]['stop_abribus'],\n",
    "        }\n",
    "    }\n",
    "    if action:\n",
    "        unique_stop['props']['action'] = action\n",
    "        \n",
    "    unique_stops.append(unique_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge stops by proximity (tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:46:45.498024Z",
     "start_time": "2019-01-27T15:46:42.212235Z"
    }
   },
   "outputs": [],
   "source": [
    "buffer_distance = 5  # meter\n",
    "multi_point_utm = reproject_geometry(multi_point.Clone(), 4326, 32618)\n",
    "buffered_points = multi_point_utm.Buffer(5)\n",
    "buffered_points_dissolved = buffered_points.UnionCascaded()\n",
    "buffered_points_dissolved_geo = reproject_geometry(buffered_points_dissolved.Clone(), 32618, 4326)\n",
    "\n",
    "buffers_file = os.path.join(output_dir, 'buffers.geojson')\n",
    "write_geometry_to_geojson(buffered_points_dissolved_geo, buffers_file)\n",
    "\n",
    "stops_file = os.path.join(output_dir, 'gtfs_stops.geojson')\n",
    "dict_to_geojson(unique_stops, stops_file, 'geom', fields_key='gtfs_props', epsg_id=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:48:19.300078Z",
     "start_time": "2019-01-27T15:46:56.847056Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_stops_merged = []\n",
    "\n",
    "for i, buffer in tqdm_notebook(enumerate(buffered_points_dissolved_geo)):\n",
    "    stops_to_merge = []\n",
    "    for stop in unique_stops:\n",
    "        if stop['geom'].Within(buffer):\n",
    "            stops_to_merge.append(stop)\n",
    "            \n",
    "    if len(stops_to_merge) > 1:\n",
    "        new_stop = stops_to_merge[0].copy()\n",
    "        merged_codes = []\n",
    "        merged_ids = []\n",
    "        \n",
    "        for stop_to_merge in stops_to_merge:\n",
    "            merged_codes.extend(stop_to_merge['gtfs_props']['stop_code'].split(','))\n",
    "            merged_ids.extend(stop_to_merge['gtfs_props']['stop_id'].split(','))\n",
    "            \n",
    "            # Copy the first stop in the list and update the keys\n",
    "            new_stop['gtfs_props']['stop_code'] = ','.join(merged_codes)\n",
    "            new_stop['gtfs_props']['stop_id'] = ','.join(merged_ids)\n",
    "            new_stop['tags']['ref'] = ';'.join(merged_codes)\n",
    "            \n",
    "        unique_stops_merged.append(new_stop)\n",
    "        \n",
    "    if len(stops_to_merge) == 1:\n",
    "        unique_stops_merged.append(stops_to_merge[0])\n",
    "            \n",
    "print('Unique stops before merge: {}'.format(len(unique_stops)))\n",
    "print('Unique stops after merge: {}'.format(len(unique_stops_merged)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T15:48:27.473763Z",
     "start_time": "2019-01-27T15:48:27.340158Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_stops_merged_file = os.path.join(output_dir, 'unique_stops_merged.geojson')\n",
    "dict_to_geojson(unique_stops_merged, unique_stops_merged_file, 'geom', 'gtfs_props', 4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate GTFS routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:07:39.189251Z",
     "start_time": "2019-01-23T08:07:39.186134Z"
    }
   },
   "outputs": [],
   "source": [
    "routes_data = gtfs_data['routes']['data']\n",
    "stop_times_data = gtfs_data['stop_times']['data']\n",
    "trips_data = gtfs_data['trips']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:07:48.928293Z",
     "start_time": "2019-01-23T08:07:48.922575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find all trips for a route\n",
    "route_trips = defaultdict(set)\n",
    "\n",
    "for trip in trips_data:\n",
    "    route_trips[trip['route_id']].add(trip['trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:08:52.954130Z",
     "start_time": "2019-01-23T08:08:52.480852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of stops per trip\n",
    "stops_counter = Counter()\n",
    "\n",
    "for stop_time in tqdm_notebook(stop_times_data):\n",
    "    stops_counter[stop_time['trip_id']] += 1\n",
    "\n",
    "stops_counter = dict(stops_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:09:03.082440Z",
     "start_time": "2019-01-23T08:09:02.639876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the longest trip per route\n",
    "longest_route_trips = []\n",
    "\n",
    "for route_id, trip_ids in tqdm_notebook(route_trips.items()):\n",
    "    trips = []\n",
    "    \n",
    "    for trip_id, stop_count in stops_counter.items():\n",
    "        if trip_id in trip_ids:\n",
    "            trips.append((trip_id, stop_count))\n",
    "            \n",
    "    trips.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    longest_route_trips.append({\n",
    "        \"route_id\": route_id,\n",
    "        \"trip_id\": trips[0][0],\n",
    "        \"stops_count\": trips[0][1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:09:12.620923Z",
     "start_time": "2019-01-23T08:09:12.616763Z"
    }
   },
   "outputs": [],
   "source": [
    "longest_route_trips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:10:13.049422Z",
     "start_time": "2019-01-23T08:10:01.064024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the stop ids to the longest route\n",
    "for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "    trip_id = longest_trip['trip_id']\n",
    "    stops = []\n",
    "    \n",
    "    for stop_time in stop_times_data:\n",
    "        if stop_time['trip_id'] == trip_id:\n",
    "            stops.append({\n",
    "                \"gtfs_id\": stop_time['stop_id'],\n",
    "                \"sequence\": int(stop_time['stop_sequence'])\n",
    "            })\n",
    "            \n",
    "    stops.sort(key=itemgetter('sequence'))\n",
    "    longest_trip['stops'] = stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:10:22.691059Z",
     "start_time": "2019-01-23T08:10:22.686057Z"
    }
   },
   "outputs": [],
   "source": [
    "longest_route_trips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:10:32.387599Z",
     "start_time": "2019-01-23T08:10:32.343452Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(longest_route_trips))\n",
    "for longest_route in tqdm_notebook(longest_route_trips):\n",
    "    print(len(longest_route['stops']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:11:23.585969Z",
     "start_time": "2019-01-23T08:10:56.242108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map the GTFS stops to the merged unique stops\n",
    "for longest_trip in tqdm_notebook(longest_route_trips):\n",
    "    for gtfs_stop in longest_trip['stops']:\n",
    "        for unique_stop in unique_stops_merged:\n",
    "            unique_stop_ids = unique_stop['gtfs_props']['stop_id'].split(',')\n",
    "            osm_id = unique_stop['props']['id']\n",
    "            name = unique_stop['tags']['name']\n",
    "            if gtfs_stop['gtfs_id'] in unique_stop_ids:\n",
    "                gtfs_stop.update({\n",
    "                    \"osm_id\": osm_id,\n",
    "                    \"name\": name\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:11:40.008895Z",
     "start_time": "2019-01-23T08:11:40.001756Z"
    }
   },
   "outputs": [],
   "source": [
    "longest_route_trips[0]['stops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:11:50.852950Z",
     "start_time": "2019-01-23T08:11:50.847833Z"
    }
   },
   "outputs": [],
   "source": [
    "for route in longest_route_trips:\n",
    "    for stop in route['stops']:\n",
    "        if 'name' not in stop:\n",
    "            print('no name')\n",
    "            print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the route names and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:12:00.745345Z",
     "start_time": "2019-01-23T08:12:00.703316Z"
    }
   },
   "outputs": [],
   "source": [
    "osm_new_route_id = -10000\n",
    "\n",
    "for i, longest_route in enumerate(tqdm_notebook(longest_route_trips)):\n",
    "    route_id = longest_route['route_id']\n",
    "    route_stops = longest_route['stops']\n",
    "    \n",
    "    first_stop = route_stops[0]['name']\n",
    "    last_stop = route_stops[-1]['name']\n",
    "\n",
    "    loop_route = 'no'\n",
    "\n",
    "    if first_stop == last_stop:\n",
    "        loop_route = 'yes'\n",
    "        print('loop route found')\n",
    "\n",
    "    for route in routes_data:\n",
    "        if route_id == route['route_id']:\n",
    "            osm_new_route_id -= 1\n",
    "            longest_route.update({\n",
    "                \"props\": {\n",
    "                    \"id\": osm_new_route_id\n",
    "                },\n",
    "                \"tags\": {\n",
    "                    \"name\": route['route_long_name'],\n",
    "#                     \"ref\": route[\"route_headsign\"],\n",
    "                    \"ref\": route['route_url'].split('route_id=')[1],\n",
    "                    \"type\": \"route\",\n",
    "                    \"route\": \"bus\",\n",
    "                    \"network\": \"STL\",\n",
    "                    \"operator\": \"STL\",\n",
    "                    \"from\": first_stop,\n",
    "                    \"to\": last_stop,\n",
    "                    \"round_trip\": loop_route,\n",
    "                    \"public_transport:version\": 2\n",
    "                },\n",
    "                \"master_route_ref\": route['route_short_name']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:12:10.547330Z",
     "start_time": "2019-01-23T08:12:10.541819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sometimes the routes file containes unique ids for trimesters\n",
    "\n",
    "route_ref_counter = Counter()\n",
    "\n",
    "for longest_route in longest_route_trips:\n",
    "    route_ref_counter[longest_route['master_route_ref']] += 1\n",
    "\n",
    "route_ref_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:36:47.946518Z",
     "start_time": "2019-01-23T08:36:47.942646Z"
    }
   },
   "outputs": [],
   "source": [
    "len(route_ref_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:36:57.800479Z",
     "start_time": "2019-01-23T08:36:57.797418Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(route_ref_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:38:35.366804Z",
     "start_time": "2019-01-23T08:38:35.362100Z"
    }
   },
   "outputs": [],
   "source": [
    "# need to reduce to 2 routes per ref max\n",
    "aggregate_longest_routes = defaultdict(list)\n",
    "\n",
    "for longest_route in longest_route_trips:\n",
    "    ref = longest_route['master_route_ref']\n",
    "    aggregate_longest_routes[ref].append(longest_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:38:45.148789Z",
     "start_time": "2019-01-23T08:38:45.145982Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregate_longest_routes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:38:54.968716Z",
     "start_time": "2019-01-23T08:38:54.954509Z"
    }
   },
   "outputs": [],
   "source": [
    "# for ref, routes in aggregate_longest_routes.items():\n",
    "# #     route_ids = [route['route_id'] for route in routes]\n",
    "# #     print(ref, route_ids)\n",
    "    \n",
    "#     a_routes = []\n",
    "#     j_routes = []\n",
    "    \n",
    "#     for route in routes:\n",
    "#         if route['route_id'].startswith('A'):\n",
    "#             a_routes.append(route)\n",
    "#         else:\n",
    "#             j_routes.append(route)\n",
    "            \n",
    "#     for a_route in a_routes:\n",
    "#         print('a routes:')\n",
    "#         print(len(a_route['stops']))\n",
    "#     for j_route in j_routes:\n",
    "#         print('j routes:')\n",
    "#         print(len(j_route['stops']))\n",
    "\n",
    "\n",
    "# Delete August routes\n",
    "filtered_routes = defaultdict(list)\n",
    "for ref, routes in aggregate_longest_routes.items():\n",
    "    if len(routes) == 4:\n",
    "        for route in routes:\n",
    "            if route['route_id'].startswith('J'):\n",
    "                filtered_routes[ref].append(route)\n",
    "    else:\n",
    "        for route in routes:\n",
    "            filtered_routes[ref].append(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:39:04.947069Z",
     "start_time": "2019-01-23T08:39:04.936186Z"
    }
   },
   "outputs": [],
   "source": [
    "for ref, routes in filtered_routes.items():\n",
    "    print(ref, len(routes))\n",
    "\n",
    "print(len(filtered_routes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:41:21.327981Z",
     "start_time": "2019-01-23T08:41:21.325683Z"
    }
   },
   "outputs": [],
   "source": [
    "# master_routes = defaultdict(list)\n",
    "\n",
    "# for route in routes_data:\n",
    "#     if route['route_id'].startswith('J'):\n",
    "#         master_routes[route['route_short_name']].append(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:41:31.144965Z",
     "start_time": "2019-01-23T08:41:31.143037Z"
    }
   },
   "outputs": [],
   "source": [
    "# master_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:41:40.898362Z",
     "start_time": "2019-01-23T08:41:40.893986Z"
    }
   },
   "outputs": [],
   "source": [
    "route_relations = []\n",
    "route_master_relations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:41:50.648347Z",
     "start_time": "2019-01-23T08:41:50.601961Z"
    }
   },
   "outputs": [],
   "source": [
    "osm_new_master_route_id = -100000\n",
    "\n",
    "for ref, routes in filtered_routes.items():\n",
    "    osm_new_master_route_id -= 1\n",
    "    names = set()\n",
    "    members = []\n",
    "#     route_ids = []\n",
    "    for route in routes:\n",
    "        for gtfs_route in routes_data:\n",
    "            if route['route_id'] == gtfs_route['route_id']:\n",
    "                names.add(gtfs_route['route_long_name'].split('Direction')[1].strip())\n",
    "#                 route_ids.append(route['route_id'])\n",
    "\n",
    "        member = {\n",
    "            \"props\": {\n",
    "                \"type\": 'relation',\n",
    "                \"ref\": route[\"props\"][\"id\"],\n",
    "                \"role\": ''\n",
    "            }\n",
    "        }\n",
    "        members.append(member)\n",
    "\n",
    "    names = list(names)\n",
    "\n",
    "    if len(names) == 2:\n",
    "        name = '{} - {}'.format(names[0], names[1])\n",
    "    elif len(names) == 1:\n",
    "        name = names[0]\n",
    "        print('Start and End have same name...')\n",
    "    else:\n",
    "        print('error')\n",
    "\n",
    "    route_master_relation = {\n",
    "        \"props\": {\n",
    "            \"id\": osm_new_master_route_id\n",
    "        },\n",
    "        \"tags\": {\n",
    "            \"name\": name,\n",
    "            \"ref\": ref,\n",
    "            \"network\": 'STL',\n",
    "            \"operator\": 'STL',\n",
    "            \"type\": \"route_master\",\n",
    "            \"public_transport:version\": 2\n",
    "        },\n",
    "        \"members\": members\n",
    "    }\n",
    "    route_master_relations.append(route_master_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:42:00.498802Z",
     "start_time": "2019-01-23T08:42:00.493730Z"
    }
   },
   "outputs": [],
   "source": [
    "route_master_relations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:47:13.895742Z",
     "start_time": "2019-01-23T08:47:13.882437Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_routes['402']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:47:23.787760Z",
     "start_time": "2019-01-23T08:47:23.774271Z"
    }
   },
   "outputs": [],
   "source": [
    "for ref, routes in filtered_routes.items():\n",
    "    for route in routes:\n",
    "        members = []\n",
    "        \n",
    "        stops = route['stops']        \n",
    "        stops.sort(key=itemgetter('sequence'))\n",
    "        \n",
    "        for stop in stops:\n",
    "            member = {\n",
    "                \"props\": {\n",
    "                    \"ref\": stop['osm_id'],\n",
    "                    \"type\": \"node\",\n",
    "                    \"role\": \"platform\"\n",
    "                }\n",
    "            }\n",
    "            members.append(member)\n",
    "            \n",
    "        route_relation = {\n",
    "            \"props\": {\n",
    "                \"id\": route['props']['id']\n",
    "            },\n",
    "            \"tags\": route['tags'],\n",
    "            \"members\": members\n",
    "        }\n",
    "        route_relations.append(route_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T08:47:33.536858Z",
     "start_time": "2019-01-23T08:47:33.531711Z"
    }
   },
   "outputs": [],
   "source": [
    "route_relations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write JOSM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T10:43:30.671251Z",
     "start_time": "2019-01-23T10:43:30.219426Z"
    }
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, 'gtfs_laval.xml')\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "root = ET.Element(\"osm\")\n",
    "root.set('version', '0.6')\n",
    "\n",
    "min_lon, max_lon, min_lat, max_lat = multi_point.GetEnvelope()\n",
    "\n",
    "bounds = ET.SubElement(root, 'bounds')\n",
    "bounds.set('minlat', str(min_lat))\n",
    "bounds.set('minlon', str(min_lon))\n",
    "bounds.set('maxlat', str(max_lat))\n",
    "bounds.set('maxlon', str(max_lon))\n",
    "\n",
    "for stop in unique_stops:\n",
    "    node = ET.SubElement(root, 'node')\n",
    "    node.set('version', '1')\n",
    "    \n",
    "    for key, value in stop.items():\n",
    "        if key == 'tags':\n",
    "            for k, v in stop['tags'].items():\n",
    "                tag = ET.SubElement(node, 'tag')\n",
    "                tag.set('k', str(k))\n",
    "                tag.set('v', str(v))\n",
    "        if key == 'props':\n",
    "            for k, v in stop['props'].items():\n",
    "                node.set(k, v)\n",
    "                \n",
    "for route_relation in route_relations:\n",
    "    relation = ET.SubElement(root, 'relation')\n",
    "    relation.set('version', '1')\n",
    "    \n",
    "    for key, value in route_relation.items():\n",
    "        if key == 'tags':\n",
    "            for k, v in route_relation['tags'].items():\n",
    "                tag = ET.SubElement(relation, 'tag')\n",
    "                tag.set('k', str(k))\n",
    "                tag.set('v', str(v))\n",
    "        if key == 'props':\n",
    "            for k, v in route_relation['props'].items():\n",
    "                relation.set(k, str(v))\n",
    "        if key == 'members':\n",
    "            for member in route_relation['members']:\n",
    "                mem = ET.SubElement(relation, 'member')\n",
    "                \n",
    "                for key, value in member.items():\n",
    "                    if key == 'props':\n",
    "                        for k, v in member['props'].items():\n",
    "                            mem.set(k, v)\n",
    "                            \n",
    "for route_master_relation in route_master_relations:\n",
    "    relation = ET.SubElement(root, 'relation')\n",
    "    relation.set('version', '1')\n",
    "    \n",
    "    for key, value in route_master_relation.items():\n",
    "        if key == 'tags':\n",
    "            for k, v in route_master_relation['tags'].items():\n",
    "                tag = ET.SubElement(relation, 'tag')\n",
    "                tag.set('k', str(k))\n",
    "                tag.set('v', str(v))\n",
    "        if key == 'props':\n",
    "            for k, v in route_master_relation['props'].items():\n",
    "                relation.set(k, str(v))\n",
    "        if key == 'members':\n",
    "            for member in route_master_relation['members']:\n",
    "                mem = ET.SubElement(relation, 'member')\n",
    "                \n",
    "                for key, value in member.items():\n",
    "                    if key == 'props':\n",
    "                        for k, v in member['props'].items():\n",
    "                            mem.set(k, str(v))\n",
    "                            \n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(output_file, encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T10:43:01.953952Z",
     "start_time": "2019-01-23T10:43:01.946830Z"
    }
   },
   "outputs": [],
   "source": [
    "for route_master_relation in route_master_relations:\n",
    "    print(route_master_relation['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
